{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDeujD32ClKr"
      },
      "source": [
        "## å–å¾—å¹´å ±"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9LdYpop4TP4"
      },
      "source": [
        "### 1ï¸âƒ£  åŒ¯å…¥å¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMJyrZh6Z89A"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T05v3t_u4gxF"
      },
      "source": [
        "### 2ï¸âƒ£ å»ºç«‹å‡½å¼-å–å¾—å¹´å ±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RswezCvohjXv"
      },
      "outputs": [],
      "source": [
        "def annual_report(id,y):\n",
        "  url = 'https://doc.twse.com.tw/server-java/t57sb01'\n",
        "  # å»ºç«‹ POST è«‹æ±‚çš„è¡¨å–®\n",
        "  data = {\n",
        "      \"id\":\"\",\n",
        "      \"key\":\"\",\n",
        "      \"step\":\"1\",\n",
        "      \"co_id\":id,\n",
        "      \"year\":y,\n",
        "      \"seamon\":\"\",\n",
        "      \"mtype\":'F',\n",
        "      \"dtype\":'F04'\n",
        "  }\n",
        "  try:\n",
        "    # ç™¼é€ POST è«‹æ±‚\n",
        "    response = requests.post(url, data=data)\n",
        "    # å–å¾—å›æ‡‰å¾Œæ“·å–æª”æ¡ˆåç¨±\n",
        "    link=BeautifulSoup(response.text, 'html.parser')\n",
        "    link1=link.find('a').text\n",
        "    print(link1)\n",
        "  except Exception as e:\n",
        "    print(f\"ç™¼ç”Ÿ{e}éŒ¯èª¤\")\n",
        "\n",
        "  # å»ºç«‹ç¬¬äºŒå€‹ POST è«‹æ±‚çš„è¡¨å–®\n",
        "  data2 = {\n",
        "      'step':'9',\n",
        "      'kind':'F',\n",
        "      'co_id':id,\n",
        "      'filename':link1 # æª”æ¡ˆåç¨±\n",
        "  }\n",
        "  try:\n",
        "    # ç™¼é€ POST è«‹æ±‚\n",
        "    response = requests.post(url, data=data2)\n",
        "    link=BeautifulSoup(response.text, 'html.parser')\n",
        "    link1=link.find('a')\n",
        "    # å–å¾— PDF é€£çµ\n",
        "    link2 = link1.get('href')\n",
        "    print(link2)\n",
        "  except Exception as e:\n",
        "    print(f\"ç™¼ç”Ÿ{e}éŒ¯èª¤\")\n",
        "\n",
        "  # ç™¼é€ GET è«‹æ±‚\n",
        "  try:\n",
        "    response = requests.get('https://doc.twse.com.tw' + link2)\n",
        "\n",
        "    with open(y + '_' + id + '.pdf', 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print('OK')\n",
        "  except Exception as e:\n",
        "    print(f\"ç™¼ç”Ÿ{e}éŒ¯èª¤\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e2fZDvP4j7U"
      },
      "source": [
        "### 3ï¸âƒ£ å‘¼å«å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhWwMVnSNnCW",
        "outputId": "c88b19b5-e361-48e7-b934-5d9b5948eda9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022_2330_20230606F04.pdf\n",
            "/pdf/2022_2330_20230606F04_20240421_234318.pdf\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        "annual_report('2330','112')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8llLs86CFIwr"
      },
      "source": [
        "## å¹´å ±å•ç­”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNeEBVGe4nm-"
      },
      "source": [
        "###4ï¸âƒ£ å®‰è£åŠåŒ¯å…¥ç›¸é—œå¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUn2DtL56u-K",
        "outputId": "fe4a56e6-8f00-417a-c491-7f5c4729faf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.352-py3-none-any.whl (794 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m794.4/794.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfplumber==0.10.2\n",
            "  Downloading pdfplumber-0.10.2-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20221105 (from pdfplumber==0.10.2)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber==0.10.2) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber==0.10.2)\n",
            "  Downloading pypdfium2-4.25.0-py3-none-manylinux_2_17_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber==0.10.2) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber==0.10.2) (41.0.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n",
            "  Downloading langchain_community-0.0.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1 (from langchain)\n",
            "  Downloading langchain_core-0.1.3-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.70 (from langchain)\n",
            "  Downloading langsmith-0.0.75-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber==0.10.2) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber==0.10.2) (2.21)\n",
            "Installing collected packages: faiss-cpu, typing-extensions, pypdfium2, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, tiktoken, jsonpatch, httpcore, pdfminer.six, langsmith, httpx, dataclasses-json, pdfplumber, openai, langchain-core, langchain-community, langchain\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.3 faiss-cpu-1.7.4 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.352 langchain-community-0.0.6 langchain-core-0.1.3 langsmith-0.0.75 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.6.1 pdfminer.six-20221105 pdfplumber-0.10.2 pypdfium2-4.25.0 tiktoken-0.5.2 typing-extensions-4.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai tiktoken pdfplumber==0.10.2 faiss-cpu\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# LangChain ç›¸é—œå¥—ä»¶\n",
        "from langchain.document_loaders import PDFPlumberLoader             # è®€å– PDF\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter  # å­—ä¸²åˆ‡å‰²\n",
        "from langchain.embeddings import OpenAIEmbeddings                   # åµŒå…¥æ–¹æ³•\n",
        "from langchain.vectorstores import FAISS                            # å‘é‡è³‡æ–™åº«\n",
        "from langchain.chat_models import ChatOpenAI                        # GPT æ¨¡å‹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC-KWjg54sh2"
      },
      "source": [
        "### 5ï¸âƒ£ å»ºç«‹ LangChain çš„ OpenAI æ¨¡å‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNjmx9zCGEV9",
        "outputId": "9a50fdf6-b31c-417d-a473-495eea3442d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "è«‹è¼¸å…¥é‡‘é‘°ï¼šÂ·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "os.environ['OPENAI_API_KEY'] = getpass.getpass(\"è«‹è¼¸å…¥é‡‘é‘°ï¼š\")\n",
        "llm_16k = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4axN95S4u2F"
      },
      "source": [
        "### 6ï¸âƒ£ å»ºç«‹å‘é‡è³‡æ–™åº«"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpsrgVqTPsNn"
      },
      "outputs": [],
      "source": [
        "def pdf_loader(file,size,overlap):\n",
        "  loader = PDFPlumberLoader(file)\n",
        "  doc = loader.load()\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "                          chunk_size=size,\n",
        "                          chunk_overlap=overlap)\n",
        "  new_doc = text_splitter.split_documents(doc)\n",
        "  db = FAISS.from_documents(new_doc, OpenAIEmbeddings())\n",
        "  return db\n",
        "\n",
        "db = pdf_loader('/content/112_2330.pdf',500, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8WOOFCp4z0l"
      },
      "source": [
        "### 7ï¸âƒ£ æŸ¥è©¢ç›¸é—œè³‡æ–™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRF0tJ61U5hg",
        "outputId": "436b4378-04db-43e6-d941-6da2cd61d58e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.4.1 å®¢æˆ¶\n",
            "æå‡åŒä»å•é¡Œè§£æ±ºèˆ‡å‰µæ–°çš„èƒ½åŠ›ï¼Œä»¥ç¶­æŒå°ç©å…¬å¸ç«¶çˆ­\n",
            "å„ªå‹¢ä¸¦é”åˆ°å®¢æˆ¶æ»¿æ„çš„é›™è´ç›®æ¨™ã€‚é™¤äº†å…¬å¸å…§éƒ¨è·¨çµ„ç¹” å°ç©å…¬å¸çš„å®¢æˆ¶éå¸ƒå…¨çƒï¼Œç”¢å“ç¨®é¡çœ¾å¤šï¼Œåœ¨åŠå° æœ€è¿‘äºŒå¹´åº¦ä½”å…¨å¹´åº¦åˆä½µç‡Ÿæ¥­æ”¶å…¥æ·¨é¡10%ä»¥ä¸Šä¹‹å®¢æˆ¶è³‡æ–™\n",
            "çš„å­¸ç¿’äº¤æµå¤–ï¼Œå°ç©å…¬å¸äº¦é€éã€Œå°ç£æŒçºŒæ”¹å–„æ´»å‹•ç«¶ é«”ç”¢æ¥­çš„å„å€‹é ˜åŸŸä¸­è¡¨ç¾å‚‘å‡ºã€‚å®¢æˆ¶åŒ…æ‹¬æœ‰ç„¡æ™¶\n",
            "å–®ä½ï¼šæ–°å°å¹£ä»Ÿå…ƒ\n",
            "è³½ã€ï¼Œè·¨ç”¢æ¥­åˆ†äº«æ”¹å–„æ‰‹æ³•ï¼ŒæœŸæœ›èƒ½ä»¥å°ç©å…¬å¸çš„ç¶“é©—åˆ† åœ“å» è¨­è¨ˆå…¬å¸ã€ç³»çµ±å…¬å¸å’Œæ•´åˆå…ƒä»¶è£½é€ å•†ï¼Œä¾‹ æ°‘åœ‹111å¹´ æ°‘åœ‹110å¹´\n",
            "åç¨±\n",
            "äº«ï¼Œä¿ƒé€²å…¶ä»–åœ¨åœ°ç”¢æ¥­çš„ç™¼å±•èˆ‡é€²æ­¥ï¼Œä¸¦è—‰ç”±è§€æ‘©å…¶ä»– å¦‚ï¼šAdvanced Micro Devices, Inc.ã€Amazon Web ä½”å…¨å¹´åº¦ç‡Ÿæ¥­æ”¶å…¥ ä½”å…¨å¹´åº¦ç‡Ÿæ¥­æ”¶å…¥\n",
            "é‡‘é¡ èˆ‡ç™¼è¡Œäººä¹‹é—œä¿‚ é‡‘é¡ èˆ‡ç™¼è¡Œäººä¹‹é—œä¿‚\n",
            "æ·¨é¡æ¯”ç‡ï¼ˆ%ï¼‰ æ·¨é¡æ¯”ç‡ï¼ˆ%ï¼‰\n",
            "ç”¢æ¥­çš„æ”¹å–„æ–¹æ³•ï¼Œæå‡åŒä»å•é¡Œè§£æ±ºèˆ‡å‰µæ–°èƒ½åŠ›ã€‚æ°‘åœ‹ Services, Inc.ã€Broadcom Inc.ã€Intel Corporationã€è¯\n",
            "ç”²å®¢æˆ¶ 529,649,200 23% ç„¡ 405,402,955 26% ç„¡\n",
            "_________\n",
            "èƒ½å°å°ç©å…¬å¸çš„ç‡Ÿé‹èˆ‡è²¡å‹™è¡¨ç¾ç”¢ç”Ÿè² é¢å½±éŸ¿ã€‚ å°ç©å…¬å¸çš„ç‡Ÿé‹æˆé•·åŠç”¢èƒ½çš„æŒçºŒæ“´å……è¨ˆåŠƒï¼Œä»°è³´ä¾†è‡ª çš„ç‡Ÿé‹æˆæœ¬ï¼Œå¦‚æœé€™äº›å°ˆåˆ©ä¸»å¼µå¯¦é«”æˆåŠŸé˜»æ””æœ¬å…¬å¸æ‰€\n",
            "è‹¥å°ç©å…¬å¸ç„¡æ³•å…‹æœä¸Šè¿°æŒ‘æˆ°ï¼Œå‰‡å¯èƒ½å°å…¬å¸æ¥­å‹™ã€è²¡ å¸‚å ´ä¸­å°‘æ•¸çš„ä¾›æ‡‰å•†ä»¥å¾—åˆ°å……åˆ†çš„è¨­å‚™åŠç›¸é—œæœå‹™ï¼Œå›  æä¾›çš„ç”¢å“åŠæœå‹™ä¹‹äº¤æ˜“ï¼Œäº¦å¯èƒ½æœƒåš´é‡å¹²æ“¾æœ¬å…¬å¸çš„\n",
            "å‹™ç‹€æ³åŠç¶“ç‡Ÿçµæœé€ æˆè² é¢å½±éŸ¿ã€‚ æ¡è³¼é›†ä¸­ä¹‹é¢¨éšªåŠå› æ‡‰æªæ–½ æ­¤å¯èƒ½é¢è‡¨ä¾›æ‡‰å•†ä¾›çµ¦æœ‰é™ä¸”äº¤è²¨æœŸé•·çš„æƒ…æ³ï¼Œç‚ºäº†å„ª ç‡Ÿé‹ã€‚å†è€…ï¼Œéš¨è‘—å°ç©å…¬å¸çš„è£½é€ ç‡Ÿé‹æ“´å¤§è‡³éƒ¨åˆ†åœ‹å¤–å€\n",
            "â—\u0007åŸç‰©æ–™ åŒ–ä¾›æ‡‰éˆç®¡ç†ï¼Œå°ç©å…¬å¸é‡å°äº¤è²¨å‰ç½®æœŸé€²è¡Œè©•ä¼°åŠé  åŸŸï¼Œæœ¬å…¬å¸å°±æ™ºæ…§è²¡ç”¢æ¬Šè¢«ä¾µå®³ä¹‹é¢¨éšªç®¡ç†äº¦é¢è‡¨æ›´é«˜\n",
            "éŠ·å”®é›†ä¸­ä¹‹é¢¨éšªåŠå› æ‡‰æªæ–½ å°ç©å…¬å¸éœ€åŠæ™‚ä¸¦ä»¥åˆç†çš„å¸‚å ´åƒ¹æ ¼ç²å¾—ç”Ÿç”¢ç‡Ÿé‹æ‰€éœ€ æ¸¬ï¼Œä»¥æœŸèƒ½å¤ ç›¡é‡é™ä½ä¾›æ‡‰éˆé¢¨éšªå°ç‡Ÿé‹æˆæœ¬çš„å½±éŸ¿ï¼Œ çš„æŒ‘æˆ°ã€‚ç¸±ä½¿æœ¬å…¬å¸åŠªåŠ›æ¡å–æœ‰åŠ›çš„æªæ–½ä»¥æ¸›è¼•åœ¨è©²ç­‰\n",
            "è¿‘å¹´ä¾†ï¼Œå°ç©å…¬å¸çš„å®¢æˆ¶ç¾¤èˆ‡å®¢æˆ¶çš„æ¥­å‹™æ€§è³ªå‡ºç¾é¡¯è‘— ä¹‹è¶³å¤ åŸç‰©æ–™ï¼Œä¾‹å¦‚çŸ½æ™¶åœ“ã€è£½ç¨‹ç”¨æ°£é«”ã€åŒ–å­¸åŸæ–™ã€å…‰ å°ç©å…¬å¸ä¹Ÿèˆ‡å„ä¾›æ‡‰å•†æŒçºŒæ“¬å®šå¤šé …å•†å‹™åˆä½œæ¨¡å¼èˆ‡ æ–°å€åŸŸå…§æ™ºæ…§è²¡ç”¢æ¬Šè¢«ä¾µå®³çš„é¢¨éšªï¼Œä»ç„¡æ³•ä¿è­‰æœ¬å…¬å¸\n",
            "_________\n",
            "æŒå…¶æœªä¾†ç™¼å±•å„ªå‹¢ã€‚\n",
            "æˆ‘å€‘å°‡æŒçºŒè‡´åŠ›æ–¼å„ªåŒ–è£½é€ ç‡Ÿé‹ï¼ˆåŒ…æ‹¬ã€Œæ•¸ä½åŒ–ã€æˆ‘å€‘çš„æ™¶åœ“å» ï¼‰ä¾†æé«˜æ•ˆç‡å’Œç”Ÿç”¢åŠ›ï¼Œè—‰ä»¥æ”¯æ´æ°‘åœ‹ä¸€ç™¾ä¸€å\n",
            "äºŒå¹´èˆ‡æ­¤å¾Œçš„N3é«˜åº¦é‡ç”¢ã€‚\n",
            "æˆ‘å€‘æ­£åœ¨å¢åŠ å°ç£ä»¥å¤–çš„ç”¢èƒ½ä»¥æ“´å¤§æˆ‘å€‘çš„æœªä¾†æˆé•·æ½›åŠ›ã€æ¥è§¸å…¨çƒäººæ‰ï¼Œä¸¦é€²ä¸€æ­¥æå‡å®¢æˆ¶ä¿¡ä»»ã€‚éš¨è‘—æˆ‘å€‘æ“´ åŠ‰å¾·éŸ³ é­é­å“²å“²å®¶å®¶\n",
            "å¤§å…¨çƒè¶³è·¡ä¸¦åœ¨ä¸–ç•Œå„åœ°é€²è¡Œæ‹›å‹Ÿï¼Œæˆ‘å€‘çš„é¦–è¦ä»»å‹™æ˜¯è­˜åˆ¥ã€å¸å¼•å’Œé›‡ç”¨èˆ‡å°ç©å…¬å¸æ ¸å¿ƒåƒ¹å€¼å’ŒåŸå‰‡ç›¸ç¬¦çš„äºº è‘£äº‹é•· ç¸½è£\n",
            "æ‰ï¼Œè®“æˆ‘å€‘ç„¡è«–åœ¨ä½•è™•ç‡Ÿé‹ï¼Œéƒ½èƒ½å¤ æ–¼æ‰€æœ‰å“¡å·¥é–“å»ºç«‹å°ç©å…¬å¸æ–‡åŒ–ã€‚\n",
            "010 011\n",
            "_________\n"
          ]
        }
      ],
      "source": [
        "query = \"å…¬å¸æ˜¯å¦æœ‰æ˜ç¢ºçš„æˆé•·æˆ–å‰µæ–°ç­–ç•¥?\"\n",
        "docs = db.similarity_search(query,k=3)\n",
        "for i in docs:\n",
        "    print(i.page_content)\n",
        "    print('_________')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgpzZOij438G"
      },
      "source": [
        "### 8ï¸âƒ£  åŒ¯å…¥å•ç­”ç›¸é—œå¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnsilIt1JmDs"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate # æç¤ºæ¨¡æ¿\n",
        "from langchain.chains import RetrievalQA         # å•ç­”æ¨¡çµ„"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9a6x7na46RM"
      },
      "source": [
        "### 9ï¸âƒ£  å»ºç«‹å‡½å¼-å•ç­”ç¨‹å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idLyQ6lVFMUD"
      },
      "outputs": [],
      "source": [
        "# æç¤ºæ¨¡æ¿\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"ä½ æ˜¯ä¸€å€‹æ ¹æ“šå¹´å ±è³‡æ–™èˆ‡ä¸Šä¸‹æ–‡ä½œå›ç­”çš„åŠ©æ‰‹,\\\n",
        "      å¦‚æœæœ‰æ˜ç¢ºæ•¸æ“šæˆ–æŠ€è¡“(ç”¢å“)åç¨±å¯ä»¥ç”¨æ•¸æ“šæˆ–åç¨±å›ç­”,\\\n",
        "      å›ç­”ä»¥ç¹é«”ä¸­æ–‡å’Œå°ç£ç”¨èªç‚ºä¸»ã€‚\\\n",
        "      {context}\"),\n",
        "    (\"human\", \"{question}\")])\n",
        "\n",
        "# å»ºç«‹å•ç­”å‡½å¼\n",
        "def question_and_answer(question):\n",
        "    qa = RetrievalQA.from_llm(llm=llm_16k,\n",
        "                              prompt=prompt,\n",
        "                              return_source_documents=True,\n",
        "                              retriever=db.as_retriever(\n",
        "                                  search_kwargs={'k':10}))\n",
        "    result = qa(question)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4UM2Kl148uW"
      },
      "source": [
        "### ğŸ”Ÿ å»ºç«‹è¿´åœˆé€²è¡Œå•ç­”\n",
        "\n",
        "è¼¸å…¥ç¯„ä¾‹\n",
        "```\n",
        "è¿‘ä¸€å¹´çš„ç‡Ÿæ”¶ç‹€æ³?\n",
        "ç›®å‰çš„ç”¢å“æœ‰å“ªäº›ï¼Ÿ\n",
        "ç›®å‰æ­£åœ¨é–‹ç™¼çš„é …ç›®æ˜¯?\n",
        "æœªä¾†ä¸€å¹´çš„è¨ˆç•«ï¼Ÿ\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xyejx1Ic8qQk",
        "outputId": "85e03c26-ed17-4c40-be63-4c130b6e1e4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "è¼¸å…¥å•é¡Œ:è¿‘ä¸€å¹´çš„ç‡Ÿæ”¶ç‹€æ³?\n",
            "æ ¹æ“šæä¾›çš„è³‡æ–™ï¼Œå°ç©å…¬å¸çš„ç‡Ÿæ”¶ç‹€æ³æœ‰æ‰€å¢é•·ã€‚ç‡Ÿæ¥­æ”¶å…¥æ·¨é¡åœ¨æœ€è¿‘ä¸€å¹´å¢åŠ äº†43%ï¼Œé€™ä¸»è¦æ˜¯å› ç‚ºå¹³å‡éŠ·å”®å–®åƒ¹æé«˜ã€æ™¶åœ“å‡ºè²¨é‡å¢åŠ å’Œå—åŒ¯ç‡è®Šå‹•å¢åŠ æ‰€è‡´ã€‚åŒæ™‚ï¼Œç‡Ÿæ¥­æ¯›åˆ©ä¹Ÿå¢åŠ äº†65%ï¼Œé¡¯ç¤ºå…¬å¸çš„ç‡Ÿæ¥­æ•ˆç›Šæœ‰æ‰€æå‡ã€‚\n",
            "_________\n",
            "è¼¸å…¥å•é¡Œ:ç›®å‰çš„ç”¢å“æœ‰å“ªäº›ï¼Ÿ\n",
            "æ ¹æ“šæä¾›çš„è³‡æ–™ï¼Œå°ç©å…¬å¸ç›®å‰çš„ç”¢å“æ¶µè“‹æ™ºæ…§å‹æ‰‹æ©Ÿã€ç‰©è¯ç¶²ã€è»Šç”¨é›»å­ã€æ¶ˆè²»æ€§é›»å­ç­‰é ˜åŸŸã€‚å…·é«”ç”¢å“åŒ…æ‹¬æ™ºæ…§å‹æ‰‹æ©Ÿã€ç‰©è¯ç¶²è£ç½®ã€è»Šç”¨è£½ç¨‹æŠ€è¡“ã€æ¶ˆè²»æ€§é›»å­ç”¢å“ä»¥åŠå…¶ä»–æ‡‰ç”¨æ‰€éœ€çš„åŠŸèƒ½ã€‚å°ç©å…¬å¸ä¹Ÿåœ¨ç‰¹æ®Šæ‡‰ç”¨ç©é«”é›»è·¯é ˜åŸŸå–å¾—äº†é‡å¤§é€²å±•ï¼Œæ”¯æ´é«˜æ•ˆèƒ½é‹ç®—åŠç³»çµ±å–®æ™¶ç‰‡æ‡‰ç”¨ï¼Œä¸¦æ¨å‡ºæ‡‰ç”¨æ–¼æ¶ˆè²»æ€§é›»å­ç”¢å“çš„äººå·¥æ™ºæ…§æ™ºèƒ½å…ƒä»¶ã€‚\n",
            "_________\n",
            "è¼¸å…¥å•é¡Œ:ç›®å‰æ­£åœ¨é–‹ç™¼çš„é …ç›®æ˜¯?\n",
            "ç›®å‰æ­£åœ¨é–‹ç™¼çš„é …ç›®åŒ…æ‹¬N6 RF+æŠ€è¡“ã€4å¥ˆç±³FinFETå¼·æ•ˆç‰ˆï¼ˆ4nm FinFET Plus, N4Pï¼‰æŠ€è¡“ã€ä»¥åŠåœ¨å¤§æ–¼90æ¯«ç±³ä¹˜90æ¯«ç±³çš„åŸºæ¿ä¸Šæ•´åˆå¤šå€‹ç³»çµ±çš„æŠ€è¡“ã€‚æ­¤å¤–ï¼Œé‚„æœ‰æˆåŠŸå®Œæˆå…¨çƒé¦–å€‹ä¸‰ç‰‡æ™¶åœ“å †ç–Šå…¨å±€æ›å…‰å½±åƒæ„Ÿæ¸¬å™¨æŠ€è¡“çš„é–‹ç™¼ã€‚\n",
            "_________\n",
            "è¼¸å…¥å•é¡Œ:æœªä¾†ä¸€å¹´çš„è¨ˆç•«ï¼Ÿ\n",
            "æœªä¾†ä¸€å¹´çš„è¨ˆç•«åŒ…æ‹¬æŒçºŒæ¨å‹•ä½ç¢³è£½é€ ï¼Œé‚å‘æ·¨é›¶æ’æ”¾ï¼Œä¸¦å¼·åŒ–æ°£å€™éŸŒæ€§ï¼ŒåŠ›æˆç‚ºå…¨çƒç¶ è‰²è£½é€ çš„é ˜å°è€…ã€‚æ­¤å¤–ï¼Œå°ç©å…¬å¸ä¹Ÿå°‡æŒçºŒè‡´åŠ›æ–¼å„ªåŒ–è£½é€ ç‡Ÿé‹ï¼Œæé«˜æ•ˆç‡å’Œç”Ÿç”¢åŠ›ï¼Œä¸¦å¢åŠ å°ç£ä»¥å¤–çš„ç”¢èƒ½ä»¥æ“´å¤§æœªä¾†æˆé•·æ½›åŠ›ã€‚å¦å¤–ï¼Œå°ç©å…¬å¸ä¹Ÿå°‡æŒçºŒé€²è¡Œå¤§å­¸åˆä½œè¨ˆåŠƒï¼Œæ¨å‹•åŠå°é«”æŠ€è¡“çš„ç ”ç™¼èˆ‡å‰µæ–°ã€‚\n",
            "_________\n",
            "è¼¸å…¥å•é¡Œ: \n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    question = input(\"è¼¸å…¥å•é¡Œ:\")\n",
        "    if not question.strip():\n",
        "        break\n",
        "    result=question_and_answer(question)\n",
        "    print(result['result'])\n",
        "    print('_________')\n",
        "    #print(result[\"source_documents\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzAmbDDYFDkE"
      },
      "source": [
        "## å¹´å ±ç¸½çµèˆ‡åˆ†æ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I10Pe8Y4-5F"
      },
      "source": [
        "### 1ï¸âƒ£1ï¸âƒ£ åŒ¯å…¥ LangChain ç¸½çµæ¨¡çµ„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o65edAvKXUH5"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.summarize import load_summarize_chain  # ç¸½çµæ¨¡çµ„"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### æ–¹æ³•ä¸€ï¼šå»ºç«‹å•é¡Œé—œéµå­—"
      ],
      "metadata": {
        "id": "k013k3h5lKgq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2Wz0MG5Avz"
      },
      "source": [
        "### 1ï¸âƒ£2ï¸âƒ£ ç¸½çµåŸå§‹è³‡æ–™"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å»ºç«‹é—œéµå­—ä¸²åˆ—\n",
        "key_word = ['æœ‰é—œå¸‚å ´ç­–ç•¥çš„èª¿æ•´æˆ–è®ŠåŒ–æœ‰ä½•æåŠï¼Ÿ',\n",
        "          'å…¬å¸å°æœªä¾†ä¸€å¹´çš„å±•æœ›æ˜¯ä»€éº¼ï¼Ÿ',\n",
        "          'å…¬å¸çš„ç¸½æ”¶å…¥æ˜¯å¦å¢é•·ï¼Œæ·¨åˆ©æ½¤çš„æ­£è² æƒ…æ³æ˜¯å¦æœ‰è®ŠåŒ–ï¼Ÿ',\n",
        "          'åœ‹éš›ç«¶çˆ­åŠæµ·å¤–å¸‚å ´æƒ…æ³',\n",
        "          'ç›®å‰çš„ç ”ç™¼ç‹€æ³?']\n",
        "\n",
        "data_list = []\n",
        "for word in key_word:\n",
        "    data = db.max_marginal_relevance_search(word)\n",
        "    # æ•´åˆ Document ä¸²åˆ—\n",
        "    data_list += data\n",
        "\n",
        "# å»ºç«‹æç¤ºè¨Šæ¯ä¸²åˆ—\n",
        "prompt_template = [(\"system\",\n",
        "                    \"ä»¥ä¸‹è³‡æ–™ç‚ºå…¬å¸çš„å¹´å ±è³‡è¨Š, ä½ çš„ä»»å‹™æ˜¯ç”Ÿæˆå¹´å ±æ‘˜è¦åŠåˆ†æå ±å‘Šã€‚\\n\\\n",
        "                     å¹´å ±è³‡è¨Šï¼š{text},\\\n",
        "                     è«‹ä¿ç•™é‡é»å¦‚ç‡Ÿæ”¶æ¼²è·Œã€é–‹ç™¼é …ç›®ç­‰,\\\n",
        "                     æœ€å¾Œè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡è¼¸å‡ºå ±å‘Š\")]\n",
        "prompt = ChatPromptTemplate.from_messages(messages=prompt_template)"
      ],
      "metadata": {
        "id": "37griuhHP0im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "220bNY7y5Cs2"
      },
      "source": [
        "### 1ï¸âƒ£3ï¸âƒ£  å‘¼å«å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_refine_16k = load_summarize_chain(llm=llm_16k,\n",
        "                                        chain_type='stuff',\n",
        "                                        prompt=prompt)\n",
        "print(chain_refine_16k.run(data_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2XTY8L7Ppnc",
        "outputId": "402c1963-ba50-41e7-ff73-5ea14c7fc2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ ¹æ“šå¹´å ±è³‡è¨Šï¼Œæœ¬å…¬å¸åœ¨ç’°å¢ƒã€ç¤¾æœƒã€å…¬å¸æ²»ç†æ–¹é¢æœ‰ä»¥ä¸‹é‡å¤§æ€§è­°é¡Œï¼š\n",
            "\n",
            "1. å…¬å¸åœ¨ç’°å¢ƒç®¡ç†æ–¹é¢æœ‰ç›¸æ‡‰çš„åˆ¶åº¦ï¼Œä¸¦ä¾æ“šæ³•è¦é€²è¡Œç®¡ç†ã€‚å…¬å¸æŒçºŒè‡´åŠ›æ–¼æ’ç¢³æ¸›é‡ï¼Œæ¨å‹•ä½ç¢³è£½é€ ï¼Œä¸¦å¼·åŒ–æ°£å€™éŸŒæ€§ï¼Œä»¥ç¬¦åˆæ°£å€™è®Šé·å› æ‡‰æ³•çš„ç›¸é—œè¦æ±‚ã€‚\n",
            "2. å…¬å¸ç©æ¥µåƒèˆ‡æ°£å€™é¢¨éšªè¾¨è­˜èˆ‡è©•ä¼°ï¼Œä¸¦å°‡å…¶ç´å…¥ä¼æ¥­é¢¨éšªç®¡ç†æµç¨‹ï¼Œä»¥è©•ä¼°é‡å¤§æ°£å€™é¢¨éšªå°å…¬å¸å¸¶ä¾†çš„æ½›åœ¨ç‡Ÿé‹èˆ‡è²¡å‹™è¡æ“Šã€‚\n",
            "3. å…¬å¸åœ¨ç¤¾æœƒæ–¹é¢æ¨å‹•å¤šå…ƒæ–‡åŒ–èåˆï¼Œæ”¯æŒå¥³æ€§åœ¨ç§‘æŠ€é ˜åŸŸçš„ç™¼å±•ï¼Œä¸¦ä¸”é€éå„é …è¨ˆåŠƒå’Œæ´»å‹•ï¼Œæå‡å¹´è¼•ä¸–ä»£çš„å­é“æ„è­˜ã€‚\n",
            "\n",
            "æ­¤å¤–ï¼Œå…¬å¸ä¹Ÿåœ¨è²¡å‹™ç‹€æ³èˆ‡ç¶“ç‡Ÿçµæœæ–¹é¢å–å¾—äº†ä¸€äº›æˆå°±ï¼ŒåŒ…æ‹¬ç‡Ÿæ”¶å¢é•·ã€ç ”ç™¼æŠ•å…¥ã€å¸‚å ´è¦æ¨¡æ“´å¤§ç­‰ã€‚\n",
            "\n",
            "ç¸½çš„ä¾†èªªï¼Œå…¬å¸åœ¨æ°£å€™è®Šé·å› æ‡‰ã€é¢¨éšªç®¡ç†ã€ç¤¾æœƒè²¬ä»»å’Œè²¡å‹™ç‹€æ³æ–¹é¢éƒ½æœ‰ç›¸æ‡‰çš„æ”¿ç­–å’Œæªæ–½ï¼Œä¸¦ä¸”å–å¾—äº†ä¸€äº›æˆå°±ã€‚æœªä¾†ï¼Œå…¬å¸å°‡æŒçºŒé—œæ³¨æ°£å€™è®Šé·ç›¸é—œæ³•è¦çš„æ›´æ–°ï¼Œä¸¦èˆ‡åˆ©å®³é—œä¿‚äººå…±åŒåŠªåŠ›ï¼Œä»¥ç¶­æŒé•·æœŸçš„æ°¸çºŒç™¼å±•ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### æ–¹æ³•äºŒï¼šé—œéµå­—è¯æƒ³"
      ],
      "metadata": {
        "id": "zVjkjlGPlUOw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtiJJipA5I9-"
      },
      "source": [
        "### 1ï¸âƒ£4ï¸âƒ£  æå–é—œéµå­—"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "\n",
        "output_parser = CommaSeparatedListOutputParser()\n",
        "\n",
        "word_prompt=ChatPromptTemplate.from_messages(messages=[\n",
        "    (\"human\",\"å¾{input}è¯æƒ³å‡º4å€‹èˆ‡å¹´å ±åˆ†ææœ‰é—œçš„é‡è¦é—œéµå­—,\"\\\n",
        "     \"è«‹ç¢ºä¿å›ç­”å…·æœ‰å…·æœ‰é—œè¯æ€§ã€å¤šæ¨£æ€§å’Œè®ŠåŒ–æ€§ã€‚ \\n \"\n",
        "     \"åƒ…å›è¦†é—œéµå­—, ä¸¦ä»¥åŠå½¢é€—è™Ÿèˆ‡ç©ºæ ¼ä¾†åˆ†éš”ã€‚ä¸è¦åŠ å…¥å…¶ä»–å…§å®¹\"\n",
        "    \"\")]\n",
        ")\n",
        "word_chain = LLMChain(llm=llm_16k, prompt=word_prompt)\n",
        "output_parser.parse(word_chain('å…¬å¸çš„ç‡Ÿæ”¶ç‹€æ³å¦‚ä½•ï¼Ÿ')['text'])"
      ],
      "metadata": {
        "id": "zMeR0jjh2_5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30787ed5-e446-4ef7-e514-25c60e85ad26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['æˆé•·', 'åˆ©æ½¤ç‡', 'å¸‚å ´ä»½é¡', 'ç¾é‡‘æµé‡']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKilRAeA5GNG"
      },
      "source": [
        "### 1ï¸âƒ£5ï¸âƒ£ è¨­å®š AI è§’è‰²è®“å…¶ä¾æ“šé—œéµå­—ä¾†é€²è¡Œåˆ†æå ±å‘Š"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_prompt=ChatPromptTemplate.from_messages(messages=[\n",
        "    (\"system\",\"ä½ ç¾åœ¨æ˜¯ä¸€ä½å°ˆæ¥­çš„è‚¡ç¥¨åˆ†æå¸«,\"\n",
        "    \"ä½ æœƒä»¥è©³ç´°ã€åš´è¬¹çš„è§’åº¦é€²è¡Œå¹´å ±åˆ†æ, é‡å°{output}é€²è¡Œåˆ†æä¸¦æåŠé‡è¦æ•¸å­—\\\n",
        "    ,ç„¶å¾Œç”Ÿæˆä¸€ä»½å°ˆæ¥­çš„è¶¨å‹¢åˆ†æå ±å‘Šã€‚\"),\n",
        "    (\"human\",\"{text}\")])\n",
        "\n",
        "data_chain = LLMChain(llm=llm_16k, prompt=data_prompt)"
      ],
      "metadata": {
        "id": "y4nY5fkpVKlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3_A78R65LAd"
      },
      "source": [
        "### 1ï¸âƒ£6ï¸âƒ£ æ•´åˆå‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_chain(input):\n",
        "    # æœå°‹ã€Œå•é¡Œã€çš„ç›¸é—œè³‡æ–™\n",
        "    data = db.max_marginal_relevance_search(input)\n",
        "\n",
        "    # ç¬¬ä¸€å€‹ Chain å…ƒä»¶, å»ºç«‹ã€Œé—œéµå­—ã€ä¸²åˆ—\n",
        "    word = word_chain(input)\n",
        "    word_list = output_parser.parse(word['text'])\n",
        "\n",
        "    # æœå°‹ã€Œé—œéµå­—ã€çš„ç›¸é—œè³‡æ–™\n",
        "    for i in word_list:\n",
        "      data += db.max_marginal_relevance_search(i,k=2)\n",
        "    word_list.append(input)\n",
        "\n",
        "    # ç¬¬äºŒå€‹ Chain å…ƒä»¶, ç”Ÿæˆåˆ†æå ±å‘Š\n",
        "    result = data_chain({'output':word_list,'text':data})\n",
        "\n",
        "    return result['text']"
      ],
      "metadata": {
        "id": "YWKb8jEydsoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT7XPS8z5NS4"
      },
      "source": [
        "### 1ï¸âƒ£7ï¸âƒ£ å‘¼å«å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = 'å…¬å¸çš„ç‡Ÿæ”¶ç‹€æ³å¦‚ä½•ï¼Ÿ'\n",
        "print(analyze_chain(input))"
      ],
      "metadata": {
        "id": "e-NHDVzqHOsU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}